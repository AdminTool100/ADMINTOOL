import requests
import json
import lightgbm as lgb
import pandas as pd
from fastapi import FastAPI
from fastapi.responses import JSONResponse
import os
import time
from threading import Thread

app = FastAPI()
model = None
trained_sessions = set()
TRAINED_FILE = "trained_sessions.json"

# Load phiÃªn Ä‘Ã£ huáº¥n luyá»‡n náº¿u cÃ³
if os.path.exists(TRAINED_FILE):
    try:
        with open(TRAINED_FILE, "r") as f:
            trained_sessions = set(json.load(f))
        print(f"ğŸ“ ÄÃ£ load {len(trained_sessions)} phiÃªn tá»« {TRAINED_FILE}")
    except:
        trained_sessions = set()
else:
    print("ğŸ“ ChÆ°a cÃ³ file trained_sessions.json")

# Ghi láº¡i cÃ¡c phiÃªn Ä‘Ã£ huáº¥n luyá»‡n
def save_trained_sessions():
    try:
        with open(TRAINED_FILE, "w") as f:
            json.dump(sorted(list(trained_sessions)), f)
        print(f"ğŸ’¾ ÄÃ£ lÆ°u {len(trained_sessions)} phiÃªn vÃ o {TRAINED_FILE}")
    except Exception as e:
        print("âŒ Lá»—i ghi file trained_sessions.json:", e)

# Láº¥y dá»¯ liá»‡u tá»« API
def fetch_data():
    try:
        res = requests.get("https://saolo-binhtool.onrender.com/api/taixiu/history")
        res.raise_for_status()
        lines = res.text.strip().splitlines()
        data = [json.loads(line) for line in lines if line.strip()]
        return data
    except Exception as e:
        print("âŒ Lá»—i fetch_data:", e)
        return []

# Táº¡o Ä‘áº·c trÆ°ng tá»« dá»¯ liá»‡u
def build_features(data, depth=5):
    rows = []
    for i in range(depth, len(data)):
        row = {}
        for j in range(depth):
            item = data[i - j]
            row[f'd{j+1}_1'] = item['dice'][0]
            row[f'd{j+1}_2'] = item['dice'][1]
            row[f'd{j+1}_3'] = item['dice'][2]
            row[f'total{j+1}'] = item['total']
        row["label"] = 1 if data[i]["result"] == "TÃ i" else 0
        rows.append(row)
    return pd.DataFrame(rows)

# Luá»“ng huáº¥n luyá»‡n ná»n
def auto_train():
    global model, trained_sessions
    print("ğŸŸ¡ Khá»Ÿi Ä‘á»™ng luá»“ng huáº¥n luyá»‡n tá»± Ä‘á»™ng...")
    while True:
        data = fetch_data()
        if len(data) < 15:
            print("âš ï¸ Dá»¯ liá»‡u chÆ°a Ä‘á»§ Ä‘á»ƒ huáº¥n luyá»‡n.")
            time.sleep(5)
            continue

        latest_session = data[0]["session"]
        if latest_session in trained_sessions:
            print(f"â© PhiÃªn {latest_session} Ä‘Ã£ huáº¥n luyá»‡n.")
            time.sleep(2)
            continue

        print(f"ğŸ”„ Äang huáº¥n luyá»‡n phiÃªn {latest_session}...")
        df = build_features(data)
        X = df.drop("label", axis=1)
        y = df["label"]

        model = lgb.LGBMClassifier(n_estimators=200, learning_rate=0.1)
        model.fit(X, y)

        trained_sessions.add(latest_session)
        save_trained_sessions()
        print(f"âœ… Huáº¥n luyá»‡n xong phiÃªn {latest_session}")
        time.sleep(2)

# Khá»Ÿi Ä‘á»™ng huáº¥n luyá»‡n ná»n
@app.on_event("startup")
def start_background():
    Thread(target=auto_train, daemon=True).start()

# Endpoint chÃ­nh
@app.get("/")
def home():
    return {"message": "ğŸ¤– API Dá»± Ä‘oÃ¡n TÃ i/Xá»‰u AI Ä‘ang hoáº¡t Ä‘á»™ng."}

# Dá»± Ä‘oÃ¡n káº¿t quáº£ phiÃªn tiáº¿p theo
@app.get("/predict")
def predict():
    global model
    data = fetch_data()
    if len(data) < 10 or model is None:
        return JSONResponse(content={"error": "âš ï¸ Thiáº¿u dá»¯ liá»‡u hoáº·c chÆ°a huáº¥n luyá»‡n xong"})

    latest_df = build_features(data[-10:], depth=5)
    latest = latest_df.drop("label", axis=1).iloc[-1:]
    prob = model.predict_proba(latest)[0]
    du_doan = "TÃ i" if prob[1] > prob[0] else "Xá»‰u"

    current = data[0]
    return {
        "current_session": current["session"],
        "dice": current["dice"],
        "total": current["total"],
        "result": current["result"],
        "next_session": current["session"] + 1,
        "du_doan_AI": du_doan,
        "confidence": f"{round(max(prob)*100, 2)}%",
        "AI": "AI NÃ‚NG CAO MR_SIMON",
        "Telegram": "@ExTaiXiu2010"
    }